{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mike/git/computational_astro/astro_iqa/data/processed/som_objects_catalog.hdf5\n",
      "Overview of the catalog:\n",
      "<Table length=2104028>\n",
      "    name     dtype \n",
      "----------- -------\n",
      "    FITS_ID bytes12\n",
      "     CCD_ID   uint8\n",
      "  OBJECT_ID bytes32\n",
      "       ISO0 float32\n",
      " BACKGROUND float32\n",
      "ELLIPTICITY float32\n",
      " ELONGATION float32\n",
      " CLASS_STAR float32\n",
      "      FLAGS   int16\n",
      "    EXPTIME float32\n",
      "    X_IMAGE float32\n",
      "    Y_IMAGE float32\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    root_path = \"/content/\"+iqa_root\n",
    "else:\n",
    "    root_path = \"/home/mike/git/computational_astro/astro_iqa\"\n",
    "\n",
    "data_path = \"data/processed\"\n",
    "catalog_name = \"som_objects_catalog.hdf5\"\n",
    "\n",
    "# Read the catalog with pandas\n",
    "filename = os.path.join(root_path, data_path, catalog_name)\n",
    "print(filename)\n",
    "columns = [\"OBJECT_ID\", \"FITS_ID\", \"CCD_ID\", \"ISO0\", \"BACKGROUND\", \"ELLIPTICITY\", \"ELONGATION\", \"CLASS_STAR\", \"FLAGS\", \"EXPTIME\"]\n",
    "# catalog = pd.read_hdf(filename, columns=columns)\n",
    "catalog = Table.read(filename, path=\"som_catalog\", format=\"hdf5\")\n",
    "\n",
    "print(\"Overview of the catalog:\")\n",
    "print(catalog.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          OBJECT_ID   FITS_ID  CCD_ID\n",
      "0  057970e69b654b1ea6066ff6e2ceb89a  1013974p       1\n",
      "1  fe42a43758b8437eb89fb3f4c384f708  1013974p       1\n",
      "2  e0ff049eb93645f68b640c94e865a079  1013974p       1\n",
      "3  fdc5c1ff1e9048b09c97c55942e9a446  1013974p       1\n",
      "4  a360c4f1d508437b9ae022fb1334d1cb  1013974p       1\n",
      "                               OBJECT_ID   FITS_ID  CCD_ID\n",
      "500000  c6c3b983afa9452f9b3cab955b41cbcc  1625583p       8\n",
      "500001  328fb32cc7bd417685c7822af50b7278  1625583p       8\n",
      "500002  f5f936fab1e44b088dffdc09be0dc449  1625583p       8\n",
      "500003  0d10fd417e7044228f1b8be0561c4336  1625583p       8\n",
      "500004  e9efd5dfd0524187bbdecb7e8118d2c2  1625583p       8\n"
     ]
    }
   ],
   "source": [
    "catalog_df = catalog.to_pandas()\n",
    "\n",
    "# Select the columns for the definition of fits/objects mapping\n",
    "mapping_names = [\"OBJECT_ID\", \"FITS_ID\", \"CCD_ID\"]\n",
    "catalog_df = catalog_df[mapping_names]\n",
    "\n",
    "# Convert the OBJECT_ID to string\n",
    "catalog_df[\"OBJECT_ID\"] = catalog_df[\"OBJECT_ID\"].apply(lambda x: x.decode('utf-8'))\n",
    "catalog_df[\"FITS_ID\"] = catalog_df[\"FITS_ID\"].apply(lambda x: x.decode('utf-8'))\n",
    "\n",
    "print(catalog_df.head())\n",
    "print(catalog_df[500000:500005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mapping to a parquet file\n",
    "mapping_filename = os.path.join(root_path, \"data/for_modeling\", \"fits_objects_mapping.parquet.gz\")\n",
    "catalog_df.to_parquet(mapping_filename, compression=\"gzip\", engine=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the ground truth annotations to the mapping table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_mapping = \"fits_objects_mapping.parquet.gz\"\n",
    "filename_labels = \"map_images_labels.json\"\n",
    "\n",
    "data_path = \"/home/mike/git/computational_astro/astro_iqa/data/\"\n",
    "file_path = os.path.join(data_path, \"for_modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ground truth labels from /home/mike/git/computational_astro/astro_iqa/data/for_modeling/map_images_labels.json\n"
     ]
    }
   ],
   "source": [
    "# Reading fits / ground truth labels\n",
    "print(f\"Reading ground truth labels from {os.path.join(file_path, filename_labels)}\")\n",
    "with open(os.path.join(file_path, filename_labels), 'r') as f:\n",
    "    labels_gt = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading fits / object mapping\n",
    "# mapping_fits_obj = pd.read_parquet(os.path.join(file_path, filename_mapping), engine='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform into a dictionary in order to get columns\n",
    "annotations_dict = {\n",
    "    \"Image_id\": list(labels_gt[\"annotations\"].keys()),\n",
    "    \"Label\": list(labels_gt[\"annotations\"].values())\n",
    "}\n",
    "\n",
    "annotations = pd.DataFrame(annotations_dict)\n",
    "\n",
    "# A few corrections\n",
    "# split multiple labels into separate columns\n",
    "annotations[['Label1', 'Label2']] = annotations['Label'].str.split(', ', expand=True)\n",
    "# Delete the original column\n",
    "annotations = annotations.drop(columns=['Label'])\n",
    "# Add a p to the Image_id column\n",
    "annotations['Image_id'] = annotations['Image_id'].astype(str) + 'p'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the ground truth labels to the mapping\n",
    "def add_ground_truth_labels(row, annotations):\n",
    "    image_id = row[\"FITS_ID\"]\n",
    "    label1 = annotations.loc[annotations[\"Image_id\"] == image_id, \"Label1\"].values[0]\n",
    "    label2 = annotations.loc[annotations[\"Image_id\"] == image_id, \"Label2\"].values[0]\n",
    "    return [label1, label2]\n",
    "\n",
    "catalog_df[[\"gt_label1\", \"gt_label2\"]] = catalog_df.apply(lambda row: add_ground_truth_labels(row, annotations), result_type=\"expand\", axis=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_df.to_parquet(os.path.join(file_path, filename_mapping), compression=\"gzip\", engine=\"auto\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro_quality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
